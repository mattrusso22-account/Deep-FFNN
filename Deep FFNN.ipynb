{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing suitable values for the epochs, batch size and learning rate\n",
    "epochs = 100\n",
    "batch_size= 10\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the data to torch tensors and normalize it \n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "transforms.Normalize((0.1307), ((0.3081)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training set and testing set\n",
    "trainset = torchvision.datasets.MNIST('mnist', train=True, \n",
    "download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST('mnist', train=False,download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training loader and testing loader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "shuffle=False, num_workers=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattrusso/opt/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/Users/mattrusso/opt/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "# Computing the shape of the training set and testing set\n",
    "trainset_shape = trainloader.dataset.train_data.shape\n",
    "testset_shape = testloader.dataset.test_data.shape\n",
    "\n",
    "# Printing the computed shapes\n",
    "print(trainset_shape, testset_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "# Computing the size of the minibatch for training set and testing set\n",
    "trainset_batchsize = trainloader.batch_size\n",
    "testset_batchsize = testloader.batch_size\n",
    "\n",
    "# Printing sizes of the minibatch\n",
    "print(trainset_batchsize, testset_batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):    \n",
    "        # Parameters of the net\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28 * 1, 175)\n",
    "        self.fc2 = nn.Linear(175, 35)\n",
    "        self.fc3 = nn.Linear(35, 55)\n",
    "        self.fc4 = nn.Linear(55, 50)\n",
    "        self.fc5 = nn.Linear(50, 70)\n",
    "        self.fc6 = nn.Linear(70, 10)\n",
    "\n",
    "    def forward(self, x):    \n",
    "        # Forward pass\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()   \n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for batch_idx, data_target in enumerate(trainloader):\n",
    "    data = data_target[0]\n",
    "    target = data_target[1]\n",
    "    data = data.view(-1, 28 * 28)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Completing a forward pass\n",
    "    output = model(data)\n",
    "\n",
    "    # Computing the loss, gradients and changing the weights\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the network is: 95 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    \n",
    "    # Putting each image into a vector\n",
    "    inputs = inputs.view(-1, 28 * 28)\n",
    "    \n",
    "    # Doing the forward pass and getting the predictions\n",
    "    outputs = model(inputs)\n",
    "    _, outputs = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (outputs == labels).sum().item()\n",
    "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After experimenting with 10 different neural network architectures, the network above generated the best results. As you can see, the accuracy of the network is 95%. It turns out that a batch size on the smaller side with a relatively high epoch value did well on our network. Since we had a value of 100 for epochs, I thought it was important to have a learning rate of 0.01. With a small learning rate, I wanted epochs value to be higher so the model could adapt to our problem more efficiently.  A smaller batch size tends to usually help with a lower generalization error. After reviewing your video in the instructional material folder, starting my first hidden layer with a larger value, improved my network accuracy by a few percents. Other experiments were not as effective and performance dropped significantly. Experiement number 5 had a much larger batch size of 400 and a learning rate of 0.8. I am starting to think that the closer the learning rate value is to 1, the more unstable the training is. It seems as if using 0.01 or 0.001 is the safest value to use as long as the number of epochs is higher. I believe I have started to find the trend and how to carefully pick suitable hyperparameters for your neural network. After finding suitable values for your hidden layers, I think learning rate may be the most important hyperparamter in neural networks. Ensuring it goes hand in hand with the epoch value can enhance the accuracy of your network and associated layers. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
